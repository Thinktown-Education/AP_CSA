## 漂流瓶（Message-in-a-Bottle）——测试计划

版本：1.0

作者：自动生成（基于 `piaoliuping.md` 的需求）

日期：2025-10-24

---

## 一、项目简介

该项目为一款“漂流瓶”应用，核心功能包括用户注册/登录、创建漂流瓶（支持匿名与图片上传）、随机捡瓶并查看详情、评论/回复、点赞/收藏、以及超时强制丢回功能。系统由前端页面、后端服务和数据库三部分构成。

## 二、测试目标与范围

- 目标：验证系统满足功能性需求与主要非功能性需求（性能、稳定性、安全、可用性）。
- 范围：覆盖 `piaoliuping.md` 中列出的所有功能点与关键边界/异常情况；不包括第三方服务的深度测试（如云存储内部实现），但包括对接正确性验证。

## 三、需求映射（来自 piaoliuping.md）

功能需求：
1. 用户：登录、注册
2. 创建漂流瓶并保存
3. 匿名选项
4. 图片上传
5. 随机获取漂流瓶
6. 获取漂流瓶信息（查看详情）
7. 丢回海里（用户手动／超时强制）
8. 评论/回复漂流瓶
9. 点赞/收藏漂流瓶

非功能需求（隐含）：
- 图片大小/类型限制
- 并发与响应时间（随机获取、上传）
- 身份验证与权限控制
- 数据持久性

## 四、测试策略

- 测试类型：单元测试（开发侧）、集成测试（后端+数据库、后端+存储）、端到端功能测试（前端->后端->DB）、非功能测试（性能、负载、安全、可用性）、边界/异常测试。
- 优先级：按用户可见性与故障影响划分（P0：登录/注册、创建/保存、随机获取；P1：图片上传、评论/回复、点赞；P2：收藏、超时丢回的自动行为监控）。
- 通过标准：测试用例的“预期结果”与实际结果一致；关键路径（P0）在回归测试中 100% 通过；P1/P2 中严重缺陷需修复再测。

## 五、测试环境与工具

- 测试环境：
  - 前端：Chrome 最新稳定版、Firefox（必要时）、移动端模拟器（可选）。
  - 后端：开发/测试服务器（可用本地或容器），数据库（MySQL/Postgres/MongoDB，根据实现）；文件存储：本地或模拟 S3。
  - 网络：局域网与受限带宽模拟（用于性能边界）。
- 工具建议：Postman / HTTPie（接口测试）、Selenium 或 Playwright（端到端）、JMeter 或 k6（性能测试）、OWASP ZAP（安全扫描）、脚本语言（Python/Node）用于自动化脚本及生成测试数据。

## 六、测试数据准备原则

- 用户账号：至少准备 3 类账号：正常用户A、正常用户B（用来相互评论/点赞）、异常/边界用户（未完成注册或被锁定）。
- 漂流瓶样本：普通文本、含表情、含特殊字符、仅图片、图片+文本。
- 图片：多种格式（jpg/png/gif）、大小边界（100KB、1MB、5MB、超过限制）、错误格式（.exe、.svg 若不支持）。

## 七、功能测试用例（示例，表格化后可扩展）

说明：每条用例包含 ID、前置条件、步骤、输入、预期结果、优先级。

- TC-F01：用户注册（P0）
  - 前置：无
  - 步骤：打开注册页面->填写合法用户名/邮箱/密码->提交
  - 输入：有效邮箱、符合规则的密码
  - 预期：返回注册成功，数据库新增用户记录，用户可登录

- TC-F02：用户登录（P0）
  - 前置：用户已注册
  - 步骤：在登录页面输入正确账号密码->提交
  - 预期：登录成功，收到有效会话/Token，能访问受保护接口

- TC-F03：创建漂流瓶并保存（含文本，P0）
  - 前置：用户已登录
  - 步骤：进入“写漂流瓶”页面->填写内容->选择“非匿名”->提交
  - 预期：成功保存，数据库中有漂流瓶记录，作者字段为当前用户，前端显示成功提示

- TC-F04：匿名创建漂流瓶（P0）
  - 前置：用户已登录
  - 步骤：填写内容->选择“匿名”->提交
  - 预期：保存成功，数据库中作者字段为匿名标识或空，前端不显示作者信息

- TC-F05：图片上传（P1）
  - 前置：用户已登录
  - 步骤：在创建漂流瓶时上传图片（合法jpg<=2MB）->提交
  - 预期：图片上传成功并能在漂流瓶详情中查看，返回图片 URL，数据库关联图片路径

- TC-F06：图片上传超出大小限制（P1，负例）
  - 输入：图片 6MB（若限制 5MB）
  - 预期：上传被拒绝，返回友好错误信息并不保存

- TC-F07：随机获取漂流瓶（P0）
  - 前置：数据库中存在不少于 N 个漂流瓶
  - 步骤：调用“捡瓶”接口 / 点击捡瓶
  - 预期：返回一个随机漂流瓶（非空），状态码 200，内容可展示

- TC-F08：查看漂流瓶详情（P0）
  - 前置：有漂流瓶 ID
  - 步骤：点击“查看详情”或请求详情接口
  - 预期：返回完整信息（内容、图片、评论数、作者/匿名标识、点赞数）

- TC-F09：评论/回复（P1）
  - 前置：用户已登录，漂流瓶存在
  - 步骤：在详情页提交评论/回复
  - 预期：评论保存并即时展示，数据库新增评论与关联关系

- TC-F10：点赞/收藏（P1）
  - 步骤：点击“点赞”或“收藏”按钮
  - 预期：接口返回成功，前端计数+1，数据库记录用户与漂流瓶的关系，重复点赞不重复计数（或可撤销）

- TC-F11：手动丢回海里（P1）
  - 步骤：用户在详情页选择“丢回”或触发删除
  - 预期：漂流瓶从可捡列表中移除或状态更新为已丢回，不能再次被捡到

- TC-F12：超时强制丢回（P2）
  - 场景：漂流瓶在“漂流”状态超过设定时长
  - 预期：定时任务/后端触发，把漂流瓶状态改为已丢回或删除；在用户端不可见

（注：上述用例为示例，建议把每条进一步表格化并为每条分配测试数据与执行者）

## 八、非功能测试用例（示例）

- 性能/负载：
  - TC-NF01：随机获取漂流瓶接口响应时间在 95% 请求下 < 300ms（单实例），并评估当并发 100/500/1000 时的响应与错误率。
  - TC-NF02：图片上传 95% 小于 1s（取决网络与存储），并评估并发上传下的吞吐与失败率。

- 稳定性：
  - TC-NF03：长时间运行（24小时）下任务调度（超时丢回）正确执行，系统内存/连接无泄漏迹象。

- 安全：
  - TC-NF04：未登录用户不能访问需要认证的接口（如创建、评论、点赞）。
  - TC-NF05：输入验证：对评论/内容进行 XSS 测试（提交含脚本的评论应被转义或拒绝）。

- 可用性：
  - TC-NF06：在上传失败或超时场景下，前端给出清晰错误并允许重试。

## 九、边界与异常情况

- 空内容创建漂流瓶（应禁止或提示）
- 上传非常大或损坏的图片（应验证并返回友好错误）
- 并发点赞（并发写冲突、计数错位）
- 用户注销/删除后其漂流瓶如何呈现（匿名/保留/删除）

## 十、验收标准

- 所有 P0 测试用例通过。
- 无明显安全漏洞（简单安全扫描无高危问题）。
- 接口响应时间与资源使用在可接受范围内（按项目给定阈值）。

## 十一、测试执行计划与责任

- 执行者：开发人员负责单元与初步集成测试；QA/测试人员或开发者负责端到端与非功能测试（按需）。
- 计划：
  - 第1天：环境准备、测试数据导入
  - 第2天：功能测试（P0->P1）
  - 第3天：非功能测试（性能、安 全）与回归
  - 第4天：修复与复测、交付测试报告

## 十二、交付物

- 测试用例清单（电子表格或 Markdown 表格）
- 测试数据集合（账号列表、图片样本）
- 性能与安全测试报告
- 最终测试计划文档（本文件）

## 十三、风险与缓解

- 风险：第三方存储/服务不可用 -> 缓解：使用本地模拟存储并做断路器
- 风险：大文件上传影响性能 -> 缓解：限制文件大小并在前端/后端双重校验

## 十四、后续建议（可选扩展）

- 增加自动化测试（Playwright/Selenium）覆盖关键用户流程
- 在 CI 中加入基础接口与性能门槛测试

---

如果你希望我把上面的测试用例进一步表格化（CSV/Excel）或生成可被 Postman/Playwright 直接导入的测试脚本，我可以继续生成并把文件放在同一目录下。是否需要我现在把用例导出为可运行的自动化脚本？
